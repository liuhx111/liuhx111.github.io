			<!DOCTYPE HTML>
			<!--
				Stellar by HTML5 UP
				html5up.net | @ajlkn
				Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
			-->
			<html>
			<head>
					<title>AR Patching</title>
					<meta charset="utf-8" />
					<meta name="viewport" content="width=device-width, initial-scale=1" />
					<link rel="stylesheet" href="assets/css/main.css" />
			</head>
				<body>

					<!-- Wrapper -->
					<div id="wrapper">

						<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="#abstract" class="active">Abstract</a></li>
								<li><a href="#demo" class="active" >Demo</a></li>
								<li><a href="#publication">Publication</a></li>
							</ul>


						</nav>

						<header id="header" class="alt">
							<h2>Interactive Robot Knowledge Patching using Augmented Reality</h2>
							<h4> <a href="https://liuhx111.github.io/">Hangxin Liu</a><sup>1*</sup>, <a>Yaofang Zhang</a><sup>1*</sup>, <a>Wenwen Si</a><sup>1</sup>, <a href="https://xuxie1031.github.io/">Xu Xie</a><sup>1</sup>, <a href="http://www.yzhu.io/">Yixin Zhu</a><sup>1</sup>, <br> <a href="http://www.stat.ucla.edu/~sczhu/index.html">Song-Chun Zhu</a><sup>1</sup> </h4>
							
							<h5><sup>1</sup> <a href="http://vcla.stat.ucla.edu/index.html">Center for Vision, Cognition, Learning, and Autonomy, UCLA</a><br>
			
		    				   <a> *Equal contributors</a>
		    				</h5>
						</header>

							<!-- Main -->
							<div id="main">

								<section id="abstract" class="main special">
										<header class="major">
											<h2><b>Abstract</b></h2>
										</header>
										<p style="text-align:left;">
											We present a novel Augmented Reality (AR) approach, through Microsoft HoloLens, to address the challenging problems of diagnosing, teaching, and patching interpretable knowledge of a robot. A Temporal And-Or graph (T-AOG) of opening bottles is learned from human demonstration and programmed to the robot. This representation yields a hierarchical structure that captures the compositional nature of the given task, which is highly interpretable for the users. By visualizing the knowledge structure represented by the T-AOG and the decision making process by parsing a T-AOG, the user can intuitively understand what the robot knows, supervise the robot's action planner, and monitor visually latent robot states (eg, the force exerted during interactions). Given a new task, through such comprehensive visualizations of robot's inner functioning, users can quickly identify the reasons of failures, interactively teach the robot with a new action, and patch it to the knowledge structure represented by the T-AOG. In this way, the robot is capable of solving similar but new tasks only through minor modifications provided by the users interactively. This process demonstrates the interpretability of our knowledge representation and the effectiveness of the AR interface.
										</p>	
									</section>

									<section id="demo" class="main special">
										<header class="major">
											<h2><b>Demo</b></h2>
										</header>
										<iframe width="480" height="360" src="https://player.vimeo.com/video/256261673" frameborder="0" allowfullscreen></iframe>
									</section>


									<!-- Publication -->
									<section id="publication" class="main special">
										<header class="major">
											<h2><b>Publication</b></h2>
										</header>
										<div>
													<li>
														<ul style="list-style-type:none">
															<li><h3 style="text-align:left;"><b>Interactive Robot Knowledge Patching using Augmented Reality</b></h3></li>
															<li><h5 style="text-align:left;"><strong>Hangxin Liu</strong>*, Yaofang Zhang*, Wenwen Si, Xu Xie, Yixin Zhu, Song-Chun Zhu (*Equal contributors)</h5></li>
															<li><h5 style="text-align:left;"><i>IEEE International Conference on on Robotics and Automation (ICRA)</i>, 2018</h5></li>
															<li><h5 style="text-align:left;">
															[<a href="http://www.yzhu.io/projects/icra18_arpatching/arpatching2018icra.pdf"><font color="blue">PDF</font></a>]
															[<a><font color="blue">Slides</font></a>]
															[<a href="https://github.com/xiaozhuchacha/AOG_AR"><font color="blue">Code</font></a>]
															</li>
															<div class="section" >
															<pre>
		      													<code class="language-latex" style = "text-align:left;">
@inproceedings{liu2018interactive,
&nbsp; &nbsp; title={Interactive Robot Knowledge Patching using Augmented Reality},
&nbsp; &nbsp; author={Liu, Hangxin and Zhang, Yaofang and Si, Wenwen and Xie, Xu and Zhu, Yixin and Zhu, Song-Chun},
&nbsp; &nbsp; booktitle={International Conference on Robotics and Automation (ICRA)},
&nbsp; &nbsp; year={2018}
&nbsp; &nbsp; organization={IEEE}	
}
																</code>
															</pre>
                    										</div>
														</ul>
													</li>
										</div>
									</section>

								</div>

								<!-- Scripts -->
								<script src="assets/js/jquery.min.js"></script>
								<script src="assets/js/jquery.scrollex.min.js"></script>
								<script src="assets/js/jquery.scrolly.min.js"></script>
								<script src="assets/js/skel.min.js"></script>
								<script src="assets/js/util.js"></script>
								<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
								<script src="assets/js/main.js"></script>

							</body>
							</html>
